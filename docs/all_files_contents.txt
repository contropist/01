File: ./README_JA.md
<h1 align="center">○</h1>

<p align="center">
    <a href="https://discord.gg/Hvz9Axh84z"><img alt="Discord" src="https://img.shields.io/discord/1146610656779440188?logo=discord&style=social&logoColor=black"/></a>
    <br>
    <br>
    <strong>オープンソースの言語モデルコンピュータ。</strong><br>
    <br><a href="https://openinterpreter.com/01">Light の予約</a>‎ ‎ |‎ ‎ <a href="https://changes.openinterpreter.com">最新情報</a>‎ ‎ |‎ ‎ <a href="https://01.openinterpreter.com/">ドキュメント</a><br>
</p>

<br>

![OI-O1-BannerDemo-2](https://www.openinterpreter.com/OI-O1-BannerDemo-3.jpg)

あなたのビルドをサポートします。[1 対 1 のサポートを申し込む。](https://0ggfznkwh4j.typeform.com/to/kkStE8WF)

<br>

> [!IMPORTANT]
> この実験的なプロジェクトは急速に開発が進んでおり、基本的な安全策が欠けています。安定した `1.0` リリースまでは、機密情報や有料サービスへのアクセスがないデバイスでのみこのリポジトリを実行してください。
>
> **これらの懸念やその他の懸念に対処するための大幅な書き換えが[ここ](https://github.com/KillianLucas/01-rewrite/tree/main)で行われています。**

<br>

**01 プロジェクト** は、AI 機器のためのオープンソースのエコシステムを構築しています。

私たちの主力オペレーティングシステムは、Rabbit R1、Humane Pin、[Star Trek computer](https://www.youtube.com/watch?v=1ZXugicgn6U) のような会話デバイスを動かすことができます。

私たちは、オープンでモジュラーでフリーであり続けることで、この分野の GNU/Linux になるつもりです。

<br>

# ソフトウェア

```shell
git clone https://github.com/OpenInterpreter/01 # リポジトリのクローン
cd 01/software # CD でソースディレクトリに移動
```

<!-- > うまくいきませんか？[セットアップガイド](https://docs.openinterpreter.com/getting-started/setup)をお読みください。 -->

```shell
brew install portaudio ffmpeg cmake # Mac OSXの依存関係のインストール
poetry install # Pythonの依存関係のインストール
export OPENAI_API_KEY=sk... # または、`poetry run 01 --local` を実行し、ローカルですべてを実行
poetry run 01 # 01 Light シミュレーターを作動させる（スペースバーを押しながら話し、放す）
```

<!-- > Windows のインストールについては、[セットアップガイド](https://docs.openinterpreter.com/getting-started/setup#windows)をお読みください。 -->

<br>

# ハードウェア

- **01 Light** は ESP32 ベースの音声インターフェースです。ビルド手順は[こちら](https://github.com/OpenInterpreter/01/tree/main/hardware/light)。買うべきもののリストは[こちら](https://github.com/OpenInterpreter/01/blob/main/hardware/light/BOM.md)。
- ご自宅のコンピューターで動作している **01 サーバー**（[下記のセットアップガイド](https://github.com/OpenInterpreter/01/blob/main/README.md#01-server)）と連動して動作します。
- **Mac OSX** と **Ubuntu** は `poetry run 01` を実行することでサポートされます（**Windows** は実験的にサポートされている）。これはスペースキーを使って 01 Light をシミュレートします。

**より多くのハードウェアをサポートし、構築するためには、皆さんの協力が必要です。** 01 は、入力（マイク、キーボードなど）、出力（スピーカー、スクリーン、モーターなど）、インターネット接続（またはローカルですべてを実行するのに十分な計算能力）があれば、どのようなデバイスでも実行できるはずです。[コントリビューションガイド →](https://github.com/OpenInterpreter/01/blob/main/CONTRIBUTING.md)

<br>

# 何をするのか？

01 は、`localhost:10001` で音声合成ウェブソケットを公開しています。

生のオーディオバイトを[ストリーミング LMC フォーマット](https://docs.openinterpreter.com/guides/streaming-response)で `/` にストリーミングすると、同じフォーマットで応答を受け取ります。

[Andrej Karpathy の LLM OS](https://twitter.com/karpathy/status/1723140519554105733) に一部インスパイアされ、[コード解釈言語モデル](https://github.com/OpenInterpreter/open-interpreter)を実行し、コンピュータの[カーネル](https://github.com/OpenInterpreter/01/blob/main/software/source/server/utils/kernel.py)で特定のイベントが発生したときにそれを呼び出します。

01 はこれを音声インターフェースで包んでいます:

<br>

<img width="100%" alt="LMC" src="https://github.com/OpenInterpreter/01/assets/63927363/52417006-a2ca-4379-b309-ffee3509f5d4"><br><br>

# プロトコル

## LMC メッセージ

このシステムのさまざまなコンポーネントと通信するために、[LMC メッセージ](https://docs.openinterpreter.com/protocols/lmc-messages)フォーマットを導入します。これは、OpenAI のメッセージフォーマットを拡張し、"computer" の役割を含むようにしたものです:

https://github.com/OpenInterpreter/01/assets/63927363/8621b075-e052-46ba-8d2e-d64b9f2a5da9

## ダイナミックシステムメッセージ

ダイナミックシステムメッセージは、LLM のシステムメッセージが AI に表示される一瞬前に、その中でコードを実行することを可能にします。

```python
# Profiles の以下の設定を編集
interpreter.system_message = r" The time is {{time.time()}}. " # 二重括弧の中は Python として実行されます
interpreter.chat("What time is it?") # ツール/API を呼び出すことなく、次のことが分かります
```

# ガイド

## 01 サーバー

デスクトップ上でサーバーを起動し、01 Light に接続するには、以下のコマンドを実行します:

```shell
brew install ngrok/ngrok/ngrok
ngrok authtoken ... # ngrok authtoken を使用
poetry run 01 --server --expose
```

最後のコマンドは、サーバーの URL を表示します。これを 01 Light のキャプティブ WiFi ポータルに入力すると、01 Server に接続できます。

## ローカルモード

```
poetry run 01 --local
```

Whisper を使ってローカル音声合成を実行したい場合、Rust をインストールする必要があります。[こちら](https://www.rust-lang.org/tools/install)の指示に従ってください。

## カスタマイズ

システムの動作をカスタマイズするには、Profiles 内の[システムメッセージ、モデル、スキルライブラリのパス](https://docs.openinterpreter.com/settings/all-settings)などを編集します。このファイルはインタープリターをセットアップするもので、Open Interpreter によって動作します。

## Ubuntu 依存関係

```bash
sudo apt-get install portaudio19-dev ffmpeg cmake
```

# コントリビューター

[![01 project contributors](https://contrib.rocks/image?repo=OpenInterpreter/01&max=2000)](https://github.com/OpenInterpreter/01/graphs/contributors)

参加方法の詳細については、[コントリビューションガイド](/CONTRIBUTING.md)をご覧ください。

<br>

# ロードマップ

01 の未来を見るには、[私達のロードマップ](/ROADMAP.md)をご覧ください。

<br>

## バックグラウンド

### [コンテキスト ↗](https://github.com/KillianLucas/01/blob/main/CONTEXT.md)

01 以前のデバイスの物語。

### [インスピレーション ↗](https://github.com/KillianLucas/01/tree/main/INSPIRATION.md)

素晴らしいアイデアは盗みたいと思うもの。

<br>

○


File: ./README.md
## Contribute to these docs
- Clone this repo
- install mintlify CLI
- run mintlify in project directory to get preview of docs
- make changes
- push changes

### Development

Install the [Mintlify CLI](https://www.npmjs.com/package/mintlify) to preview the documentation changes locally. To install, use the following command

```
npm i -g mintlify
```

Run the following command at the root of your documentation (where mint.json is)

```
mintlify dev
```

#### Troubleshooting

- Mintlify dev isn't running - Run `mintlify install` it'll re-install dependencies.
- Page loads as a 404 - Make sure you are running in a folder with `mint.json`


File: ./README_CN.md
<h1 align="center">○</h1>

<p align="center">
    <a href="https://discord.gg/Hvz9Axh84z"><img alt="Discord" src="https://img.shields.io/discord/1146610656779440188?logo=discord&style=social&logoColor=black"/></a>
    <br>
    <br>
    <strong>The open-source language model computer.（开源大语言模型计算机）</strong><br>
    <br><a href="https://openinterpreter.com/01">预订 Light‎</a>‎ ‎ |‎ ‎ <a href="https://changes.openinterpreter.com">获取更新‎</a>‎ ‎ |‎ ‎ <a href="https://01.openinterpreter.com/">文档</a><br>
</p>

<br>

![OI-O1-BannerDemo-2](https://www.openinterpreter.com/OI-O1-BannerDemo-3.jpg)

我们想帮助您构建。 [申请 1 对 1 的支持。](https://0ggfznkwh4j.typeform.com/to/kkStE8WF)

<br>

> [!IMPORTANT]
> 这个实验性项目正在快速开发中，并且缺乏基本的安全保障。在稳定的 `1.0` 版本发布之前， 仅在没有敏感信息或访问付费服务的设备上运行此存储库。

<br>

**01 项目** 正在构建一个用于 AI 设备的开源生态系统。

我们的旗舰操作系统可以为对话设备提供动力，比如 Rabbit R1、Humane Pin 或 [Star Trek computer](https://www.youtube.com/watch?v=1ZXugicgn6U)。

我们打算成为这个领域的 GNU/Linux，保持开放、模块化和免费。

<br>

# 软件

```shell
git clone https://github.com/OpenInterpreter/01 # Clone the repository
cd 01/software # CD into the source directory
```

<!-- > 不起作用？阅读我们的[安装指南](https://docs.openinterpreter.com/getting-started/setup)。 -->

```shell
brew install portaudio ffmpeg cmake # Install Mac OSX dependencies
poetry install # Install Python dependencies
export OPENAI_API_KEY=sk... # OR run `poetry run 01 --local` to run everything locally
poetry run 01 # Runs the 01 Light simulator (hold your spacebar, speak, release)
```

<!-- > 对于Windows安装，请阅读我们的[专用安装指南](https://docs.openinterpreter.com/getting-started/setup#windows)。 -->

<br>

# 硬件

- **01 Light** 是基于 ESP32 的语音接口。 [构建说明在这里。](https://github.com/OpenInterpreter/01/tree/main/hardware/light) 它与运行在你家庭电脑上的 **01 Server** ([下面有设置指南](https://github.com/OpenInterpreter/01/blob/main/README.md#01-server)) 配合使用。
- **Mac OSX** and **Ubuntu** 支持通过运行 `poetry run 01`。 这会使用你的空格键来模拟 01 Light。

**我们需要您的帮助来支持和构建更多硬件。** 01 应该能够在任何具有输入（麦克风、键盘等）、输出（扬声器、屏幕、电机等）和互联网连接（或足够的计算资源以在本地运行所有内容）的设备上运行。 [ 贡献指南 →](https://github.com/OpenInterpreter/01/blob/main/CONTRIBUTING.md)

<br>

# 它是做什么的？

01 在 `localhost:10001` 上暴露了一个语音到语音的 WebSocket。

如果你以 [LMC 格式](https://docs.openinterpreter.com/protocols/lmc-messages) 将原始音频字节流传送到 `/`，你将会以相同的格式收到其回复。

受 [Andrej Karpathy's LLM OS](https://twitter.com/karpathy/status/1723140519554105733) 的启发，我们运行了一个 [code-interpreting language model](https://github.com/OpenInterpreter/open-interpreter)，并在你的计算机 [ 内核 ](https://github.com/OpenInterpreter/01/blob/main/software/source/server/utils/kernel.py) 发生某些事件时调用它。

01 将其包装成一个语音界面：

<br>

<img width="100%" alt="LMC" src="https://github.com/OpenInterpreter/01/assets/63927363/52417006-a2ca-4379-b309-ffee3509f5d4"><br><br>

# 协议

## LMC 消息

为了与系统的不同组件进行通信，我们引入了 [LMC 消息](https://docs.openinterpreter.com/protocols/lmc-messages) 格式，它扩展了 OpenAI 的消息格式以包含一个 "computer" 角色：

https://github.com/OpenInterpreter/01/assets/63927363/8621b075-e052-46ba-8d2e-d64b9f2a5da9

## 动态系统消息

动态系统消息使您能够在 LLM 系统消息出现在 AI 前的片刻内执行代码。

```python
# Edit the following settings in Profiles
interpreter.system_message = r" The time is {{time.time()}}. " # Anything in double brackets will be executed as Python
interpreter.chat("What time is it?") # It will know, without making a tool/API call
```

# 指南

## 01 服务器

要在您的桌面上运行服务器并将其连接到您的 01 Light，请运行以下命令：

```shell
brew install ngrok/ngrok/ngrok
ngrok authtoken ... # Use your ngrok authtoken
poetry run 01 --server --expose
```

最后一个命令将打印一个服务器 URL。您可以将其输入到您的 01 Light 的 captive WiFi 门户中，以连接到您的 01 服务器。

## 本地模式

```
poetry run 01 --local
```

如果您想要使用 Whisper 运行本地语音转文本，您必须安装 Rust。请按照 [这里](https://www.rust-lang.org/tools/install) 给出的说明进行操作。

## 自定义

要自定义系统的行为，请编辑 Profiles 中的 [系统消息、模型、技能库路径](https://docs.openinterpreter.com/settings/all-settings) 等。这个文件设置了一个解释器，并由 Open Interpreter 提供支持。

## Ubuntu 依赖项

```bash
sudo apt-get install portaudio19-dev ffmpeg cmake
```

# 贡献者

[![01 project contributors](https://contrib.rocks/image?repo=OpenInterpreter/01&max=2000)](https://github.com/OpenInterpreter/01/graphs/contributors)

请查看我们的 [贡献指南](CONTRIBUTING.md) 以获取更多的参与详情。

<br>

# 路线图

访问 [我们的路线图](/ROADMAP.md) 以了解 01 的未来。

<br>

## 背景

### [背景说明 ↗](https://github.com/KillianLucas/01/blob/main/CONTEXT.md)

关于 01 之前设备的故事。

### [灵感来源 ↗](https://github.com/KillianLucas/01/tree/main/INSPIRATION.md)

我们想要从中获取优秀想法的事物。

<br>

○


File: ./favicon.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./mint.json
{
  "name": "01",
  "logo": {
    "dark": "/logo/Z-icon-white.png",
    "light": "/logo/Z-icon-black.png"
  },
  "favicon": "/favicon.png",
  "colors": {
    "primary": "#000000",
    "light": "#FFFFFF",
    "dark": "#000000",
    "background": {
      "light": "#FFFFFF",
      "dark": "#000000"
    },
    "anchors": {
      "from": "#000000",
      "to": "#000000"
    }
  },
  "topbarLinks": [
    {
      "name": "GitHub",
      "url": "https://github.com/OpenInterpreter/01"
    }
  ],
  "topbarCtaButton": {
    "name": "Join Discord",
    "url": "https://discord.com/invite/Hvz9Axh84z"
  },
  "primaryTab": {
    "name": "Home"
  },
  "navigation": [
    {
      "group": "Setup",
      "pages": [
        "setup/introduction",
        "setup/installation"
      ]
    },
    {
      "group": "Safety",
      "pages": [
        "safety/introduction",
        "safety/risks",
        "safety/measures"
      ]
    },
    {
      "group": "Server",
      "pages": [
        "server/introduction",
        "server/livekit",
        "server/light",
        "server/configure",
        "server/flags"
      ]
    },
    {
      "group": "Client",
      "pages": [
        "client/introduction",
        "client/android-ios",
        "client/desktop",
        "client/esp32",
        "client/native-ios"
      ]
    },
    {
      "group": "Hardware",
      "pages": [
        "hardware/introduction",
        {
          "group": "01 Light",
          "pages": [
            "hardware/01-light/introduction",
            "hardware/01-light/materials",
            "hardware/01-light/case",
            "hardware/01-light/assembly",
            "hardware/01-light/chip",
            "hardware/01-light/connect"
          ]
        },
        "hardware/desktop",
        "hardware/mini-phone",
        "hardware/grimes",
        "hardware/custom"
      ]
    },
    {
      "group": "Troubleshooting",
      "pages": [
        "troubleshooting/faq"
      ]
    },
    {
      "group": "Legal",
      "pages": [
        "legal/privacy-policy",
        "legal/terms-of-service"
      ]
    }
  ],
  "feedback": {
    "suggestEdit": true
  },
  "footerSocials": {
    "twitter": "https://x.com/OpenInterpreter",
    "github": "https://github.com/OpenInterpreter/01",
    "discord": "https://discord.com/invite/Hvz9Axh84z"
  }
}

File: ./README_FR.md
<h1 align="center">○</h1>

<p align="center">
    <a href="https://discord.gg/Hvz9Axh84z"><img alt="Discord" src="https://img.shields.io/discord/1146610656779440188?logo=discord&style=social&logoColor=black"/></a>
    <br>
    <br>
    <strong>Le modèle de langage d'ordinateur open-source.</strong><br>
    <br><a href="https://openinterpreter.com/01">Précommandez le Light</a>‎ ‎ |‎ ‎ <a href="https://changes.openinterpreter.com">Recevoir les mises à jour</a>‎ ‎ |‎ ‎ <a href="https://01.openinterpreter.com/">Documentation</a><br>
</p>

<br>

![OI-O1-BannerDemo-2](https://www.openinterpreter.com/OI-O1-BannerDemo-3.jpg)

Nous voulons vous aider à construire. [Postulez pour un support individuel.](https://0ggfznkwh4j.typeform.com/to/kkStE8WF)

<br>

---

⚠️ **ATTENTION** : Ce projet expérimental est en développement rapide et manque de protections de sécurité de base. Jusqu'à l'atteinte d'une version stable 1.0, veuillez faire fonctionner ce dépôt **uniquement** sur des appareils ne contenant aucune information sensible et n'ayant pas accès à des services payants.

---

<br>

**Le Projet 01** construit un écosystème open source pour les appareils d'IA.

Notre système d'exploitation phare peut alimenter des dispositifs conversationnels tels que le Rabbit R1, le Humane Pin, ou [l'ordinateur de Star Trek](https://www.youtube.com/watch?v=1ZXugicgn6U).

Nous avons l'intention de devenir le GNU/Linux de cet environnement en restant ouvert, modulaire et gratuit.

<br>

# Software

```shell
git clone https://github.com/OpenInterpreter/01 # Clone le dépôt
cd 01/software # CD dans le répertoire source
```

<!-- > Cela ne fonctionne pas ? Lisez notre [guide d'installation](https://docs.openinterpreter.com/getting-started/setup). -->

```shell
brew install portaudio ffmpeg cmake # Installe les dépendances Mac OSX
poetry install # Installe les dépendances Python
export OPENAI_API_KEY=sk... # OU exécute `poetry run 01 --local` pour tout exécuter localement
poetry run 01 # Exécute le simulateur 01 Light (maintenez votre barre d'espace, parlez, relâchez)
```

<!-- > Pour une installation sous Windows, lisez [le guide dédié](https://docs.openinterpreter.com/getting-started/setup#windows). -->

<br>

# Hardware

- Le **01 Light** est une interface vocale basée sur ESP32. Les instructions de construction sont [ici]. (https://github.com/OpenInterpreter/01/tree/main/hardware/light). Une liste de ce qu'il faut acheter se trouve [ici](https://github.com/OpenInterpreter/01/blob/main/hardware/light/BOM.md).
- Il fonctionne en tandem avec le **Server 01** ([guide d'installation ci-dessous](https://github.com/OpenInterpreter/01/blob/main/README.md#01-server)) fonctionnant sur votre ordinateur.
- **Mac OSX** et **Ubuntu** sont pris en charge en exécutant `poetry run 01` (**Windows** est pris en charge de manière expérimentale). Cela utilise votre barre d'espace pour simuler le 01 Light.

**Nous avons besoin de votre aide pour soutenir et construire plus de hardware.** Le 01 devrait pouvoir fonctionner sur tout dispositif avec entrée (microphone, clavier, etc.), sortie (haut-parleurs, écrans, moteurs, etc.) et connexion internet (ou suffisamment de puissance de calcul pour tout exécuter localement). [Guide de Contribution →](https://github.com/OpenInterpreter/01/blob/main/CONTRIBUTING.md)

<br>

# Comment ça marche ?

Le 01 expose un websocket de _speech-to-speech_ à l'adresse `localhost:10001`.

Si vous diffusez des octets audio bruts vers `/` au [format de streaming LMC](https://docs.openinterpreter.com/guides/streaming-response), vous recevrez sa réponse dans le même format.

Inspiré en partie par [l'idée d'un OS LLM d'Andrej Karpathy](https://twitter.com/karpathy/status/1723140519554105733), nous utilisons un [un modèle de langage inteprétant du code](https://github.com/OpenInterpreter/open-interpreter), et le sollicitons lorsque certains événements se produisent dans le [noyau de votre ordinateur](https://github.com/OpenInterpreter/01/blob/main/software/source/server/utils/kernel.py).

Le 01 l'encapsule dans une interface vocale :

<br>

<img width="100%" alt="LMC" src="https://github.com/OpenInterpreter/01/assets/63927363/52417006-a2ca-4379-b309-ffee3509f5d4"><br><br>

# Protocoles

## Messages LMC

Pour communiquer avec les différents composants du système, nous introduisons le [format de messages LMC](https://docs.openinterpreter.com/protocols/lmc-messages), une extension du format de message d'OpenAI qui inclut un nouveau rôle "_computer_":

https://github.com/OpenInterpreter/01/assets/63927363/8621b075-e052-46ba-8d2e-d64b9f2a5da9

## Messages Systèmes Dynamiques (Dynamic System Messages)

Les Messages Systèmes Dynamiques vous permettent d'exécuter du code à l'intérieur du message système du LLM, juste avant qu'il n'apparaisse à l'IA.

```python
# Modifiez les paramètres suivants dans Profiles
interpreter.system_message = r" The time is {{time.time()}}. " # Tout ce qui est entre doubles crochets sera exécuté comme du Python
interpreter.chat("What time is it?") # L'interpréteur connaitre la réponse, sans faire appel à un outil ou une API
```

# Guides

## 01 Server

Pour exécuter le serveur sur votre ordinateur et le connecter à votre 01 Light, exécutez les commandes suivantes :

```shell
brew install ngrok/ngrok/ngrok
ngrok authtoken ... # Utilisez votre authtoken ngrok
poetry run 01 --server --expose
```

La dernière commande affichera une URL de serveur. Vous pouvez saisir ceci dans le portail WiFi captif de votre 01 Light pour le connecter à votre serveur 01.

## Mode Local

```
poetry run 01 --local
```

Si vous souhaitez exécuter localement du speech-to-text en utilisant Whisper, vous devez installer Rust. Suivez les instructions données [ici](https://www.rust-lang.org/tools/install).

## Personnalisation

Pour personnaliser le comportement du système, modifie [`system message`, `model`, `skills library path`,](https://docs.openinterpreter.com/settings/all-settings) etc. in Profiles. Ce fichier configure un interprète alimenté par Open Interpreter.

## Dépendances Ubuntu

```bash
sudo apt-get install portaudio19-dev ffmpeg cmake
```

# Contributeurs

[![01 project contributors](https://contrib.rocks/image?repo=OpenInterpreter/01&max=2000)](https://github.com/OpenInterpreter/01/graphs/contributors)

Veuillez consulter nos [directives de contribution](CONTRIBUTING.md) pour plus de détails sur comment participer.

<br>

# Roadmap

Visitez [notre roadmap](/ROADMAP.md) pour connaitre le futur du 01.

<br>

## Background

### [Contexte ↗](https://github.com/KillianLucas/01/blob/main/CONTEXT.md)

L'histoire des appareils qui ont précédé le 01.

### [Inspiration ↗](https://github.com/KillianLucas/01/tree/main/INSPIRATION.md)

Des choses dont nous souhaitons nous inspirer.

<br>

○


File: ./style.css
/* .rounded-lg {
    border-radius: 0;
} */

/*

.rounded-sm, .rounded-md, .rounded-lg, .rounded-xl, .rounded-2xl, .rounded-3xl {
    border-radius: 0.125rem;
}

.rounded-full {
    border-radius: 0.125rem;
}

*/

.font-extrabold {
    font-weight: 600;
}

.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
    font-weight: 600;
}

.body {
    font-weight: normal;
}


File: ./hardware/custom.mdx
---
title: "Custom Hardware"
description: "Control 01 from your own device"
---

You can create custom hardware that integrates with the O1 server software running on your computer.

To use 01 with your custom hardware, run the livekit server and connect to the "Livekit is running at..." URL that is displayed:

```bash
poetry run 01 --server livekit
```

Or, run the light server and connect to the URL that is displayed:

```bash
poetry run 01 --server light
```

You may need to set additional parameters via [flags](/software/flags) depending on your setup.

---

# Usage

## Light Server

When using the light server, to transmit audio commands to 01, send LMC audio chunks to the websocket defined by your server.

### LMC Messages

To support the incoming `L`anguage `M`odel `C`omputer architecture, we extend OpenAI's messages format to include additional information, and a new role called `computer`:

<Card
  title="LMC"
  icon="link"
  href="https://docs.openinterpreter.com/protocols/lmc-messages"
>
  Read about LMC messages protocol here.
</Card>

## Livekit Server

When using the Livekit server, any of Livekit's SDKs will connect.

<Card
  title="Explore Livekit SDKs"
  icon="code"
  href="https://docs.livekit.io/client-sdk-js/"
>
  Find documentation and integration guides for all Livekit SDKs.
</Card>

File: ./hardware/desktop.mdx
---
title: "Desktop"
description: "Control the 01 from your computer"
---

<Info> Make sure that you have navigated to the `/software` directory. </Info>

To run 01 with your computer's microphone and speaker, you need to start a server and a client.

We abstract this away with a simple command:

```bash
poetry run 01
```

*Tip:* While in the `/software` directory, you can run the following command to install the `01` command system-wide:

```bash
pip install .
```

Then, simply run `01` in your terminal to start the server + client and begin speaking to your assistant.

```bash
01
```

File: ./hardware/mini-phone.mdx
---
title: "Mini Phone"
description: "A compact, dedicated device for 01"
---

![Mini Phone for 01](https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/app.png)

To create your own mini-phone for 01:

1. Install the 01 App on a small smartphone. For installation instructions, visit the [Android & iOS client page](/client/android-ios).

2. Purchase a mini smartphone to use as your dedicated 01 device:

<Card title="Mini Smartphone" icon="mobile" href="https://www.amazon.com/FDMDAF-Smartphone-Cellphone-Lightweight-Unlocked/dp/B0CYGZFC54/ref=sr_1_2">
  Buy on Amazon
</Card>

Once you have the app installed on your mini smartphone, you'll have a compact, dedicated device for interacting with 01.

File: ./hardware/introduction.mdx
---
title: "Introduction"
description: "Explore various hardware configurations for the 01 platform"
---

The 01 platform offers flexibility in hardware configurations, allowing you to create a device that suits your needs and preferences. From desktop setups to portable builds, there are multiple options to bring the 01 experience to life.

<CardGroup cols={3}>
  <Card
    title="01 Light"
    icon="circle"
    href="/hardware/01-light"
    description="Create a simplified, lightweight version of the 01 device."
  />
  <Card
    title="Desktop Setup"
    icon="desktop"
    href="/hardware/desktop"
    description="Create a powerful 01 setup using your existing computer hardware."
  />
  <Card
    title="Grimes Build"
    icon="microchip"
    href="/hardware/grimes"
    description="Build a portable 01 device inspired by Grimes' custom hardware."
  />
  <Card
    title="Custom Builds"
    icon="screwdriver-wrench"
    href="/hardware/custom"
    description="Explore unique and creative ways to build your own 01 device."
  />
  <Card
    title="Mini Phone"
    icon="mobile"
    href="/hardware/mini-phone"
    description="Transform a small smartphone into a dedicated 01 device."
  />
</CardGroup>

File: ./hardware/grimes.mdx
---
title: "Grimes Build"
description: "A simple DIY setup used by Grimes and Bella Poarch at Coachella"
---

# Grimes' Coachella 01 Build

This guide describes the simple DIY setup used by Grimes and Bella Poarch to interact with the 01 AI assistant at Coachella. The setup consists of two main components taped together:

<CardGroup cols={2}>
  <Card title="Macro Keypad" icon="keyboard" href="https://www.amazon.com/dp/B0BDRPQLW1?ref=ppx_yo2ov_dt_b_fed_asin_title&th=1">
    Purchase on Amazon
  </Card>
  <Card title="Microphone" icon="microphone" href="https://www.amazon.com/dp/B08LGWSCJD?ref=ppx_yo2ov_dt_b_fed_asin_title">
    Purchase on Amazon
  </Card>
</CardGroup>

## Assembly

1. Purchase the macro keypad and microphone using the links above.
2. Simply tape the microphone to the macro keypad.

## Setup

1. Install the [01 Desktop Client](/client/desktop) on your computer.
2. Remap the buttons on the macro keypad to trigger the hotkey that activates the 01 AI assistant.

## Usage

1. Start the 01 Desktop Client on your computer.
2. Press the remapped button on the macro keypad to activate the 01 AI assistant.
3. Speak into the attached microphone to interact with the AI.

File: ./hardware/01-light/connect.mdx
---
title: "Connect"
description: "Connect your 01 device to your 01 server"
---

### Connecting your 01 device to the server

1. Start the 01 server on your computer:
   ```
   poetry run 01 --server light
   ```
   This command starts the server and generates a URL.

   For remote connections, use:
   ```
   poetry run 01 --server light --expose
   ```
   This generates a public URL accessible from anywhere.

2. Connect your 01 device to the server using one of these methods:

   a) Hardcode credentials:
   - Modify the Wi-Fi and server credentials at the top of the `client.ino` file.
   - Flash the modified file to the ESP32.
   - This method is quick but less flexible for changing details later.

   b) Use the captive portal:
   - Power on your 01 device.
   - Connect to the '01-light' Wi-Fi network from your computer or smartphone.
   - A captive portal page should open automatically. If not, open a web browser.
   - Enter your Wi-Fi details and the server URL from step 1.
   - Click 'Connect' to save settings and connect your device.

After successful connection, your 01 device will be ready to communicate with the server.


File: ./hardware/01-light/chip.mdx
---
title: "Chip"
---

For the 01 Light project, we've chosen the M5Atom, which features an ESP32 Pico chip. This compact and powerful microcontroller is ideal for our needs, offering built-in Wi-Fi and Bluetooth capabilities, a microphone, speaker, and button.

To set up the M5Atom for use with 01 Light, please follow the instructions in our [ESP32 Setup Guide](client/esp32).

<Card title="ESP32 Setup Guide" icon="microchip" href="/client/esp32">
  Learn how to set up your M5Atom for the 01 Light project
</Card>


File: ./hardware/01-light/case.mdx
---
title: "Case"
description: "The Body of the 01 Light"
---

# Case

You can 3D print the 01 case at home. For the best quality, it's recommended to use a resin printer.

Watch this video from James at CAD9 Design for a deep dive on his design.

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/BjoO0Kt-IWM"
  frameBorder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
></iframe>

The STL files can be found [here](https://github.com/OpenInterpreter/01/tree/main/hardware/light/bodies).


File: ./hardware/01-light/introduction.mdx
---
title: "Introduction"
description: "Talk to your computer from anywhere in the world"
---

![01 Light](https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/01-light.png)

The 01 light is a handheld, push-to-talk voice interface. It's powered by an ESP32 chip that sends the user's voice over Wifi to the 01 Server, then plays back the audio it receives.

# Setup guide

<Steps>
  <Step title="Gather Materials">
    <Card title="Buy Materials" icon="basket-shopping" href="/hardware/01-light/materials">
      Get the list of components needed to build your 01 Light. Click here to view the required materials and purchase options.
    </Card>
  </Step>
  
  <Step title="3D Print the Case">
    <Card title="Print Case" icon="cube" href="/hardware/01-light/case">
      Download the 3D model files and follow instructions to print the custom case for your 01 Light.
    </Card>
  </Step>
  
  <Step title="Assemble the Device">
    <Card title="Assembly Guide" icon="screwdriver-wrench" href="/hardware/01-light/assembly">
      Step-by-step instructions on how to put together your 01 Light components inside the 3D printed case.
    </Card>
  </Step>
  
  <Step title="Flash the ESP32">
    <Card title="Program the Chip" icon="microchip" href="/hardware/01-light/chip">
      Learn how to flash the ESP32 with the 01 Light firmware to enable its core functionality.
    </Card>
  </Step>
  
  <Step title="Connect to Server">
    <Card title="Setup Connection" icon="wifi" href="/hardware/01-light/connect">
      Configure your 01 Light to connect to the 01 Server and start using your new voice interface.
    </Card>
  </Step>
</Steps>


File: ./hardware/01-light/assembly.mdx
---
title: "Assembly"
description: "How to build your 01 Light"
---

Watch this video from James at CAD9 Design for a detailed guide on assembling your 01.

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/37a5bgvoZy8"
  frameBorder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
></iframe>

## Wiring Diagram

![Wiring Diagram](/hardware/light/wiring-diagram.jpg)


File: ./hardware/01-light/materials.mdx
---
title: "Materials"
description: "Bill of Materials for the 01 Light"
---

# 01 Light Bill of Materials

| Part Name                                               | Part Number | How Many | Unit Price | Units per order | Purchase Link                                                     | Mouser Link                                          | $42.38 |
| :------------------------------------------------------ | :---------- | :------- | :--------- | :-------------- | :---------------------------------------------------------------- | :--------------------------------------------------- | -----: |
| ATOM Echo Smart Speaker Development Kit                 | C008-C      | 1        | $13.50     | 1               | https://shop.m5stack.com/products/atom-echo-smart-speaker-dev-kit | https://www.mouser.com/ProductDetail/170-C008-C      |        |
| PowerBoost 1000 Charger                                 | 2465        | 1        | $19.95     | 1               | https://www.adafruit.com/product/2465                             | https://www.mouser.com/ProductDetail/485-2465        |        |
| Tactile Switches 12MM TACTILE PB SWITCH                 | FSM103      | 1        | $0.28      | 1               | https://www.mouser.com/ProductDetail/506-FSM103                   | https://www.mouser.com/ProductDetail/506-FSM103      |        |
| Slide Switches DPDT THRU HOLE .3A                       | JS202011CQN | 1        | $0.70      | 1               | https://www.mouser.com/ProductDetail/611-JS202011CQN              | https://www.mouser.com/ProductDetail/611-JS202011CQN |        |
| Lithium Ion Polymer Battery - 3.7v 500mAh               | 1578        | 1        | $7.95      | 1               | https://www.adafruit.com/product/1578                             | https://www.mouser.com/ProductDetail/485-1578        |        |
| Wires                                                   |             |          |            |                 |                                                                   |                                                      |  $4.80 |
| Silicone Cover Stranded-Core Wire - 25ft 26AWG - Black  | 1881        | 1        | $0.95      | 1               | https://www.adafruit.com/product/1881                             | https://www.mouser.com/ProductDetail/485-1881        |        |
| Silicone Cover Stranded-Core Wire - 25ft 26AWG - Red    | 1877        | 1        | $0.95      | 1               | https://www.adafruit.com/product/1877                             | https://www.mouser.com/ProductDetail/485-1877        |        |
| Silicone Cover Stranded-Core Wire - 25ft 26AWG - Yellow | 1879        | 1        | $0.95      | 1               | https://www.adafruit.com/product/1879                             | https://www.mouser.com/ProductDetail/485-1879        |        |
| Premium Male/Male Jumper Wires - 20 x 3" (75mm)         | 1956        | 1        | $1.95      | 20              | https://www.adafruit.com/product/1956                             | https://www.mouser.com/ProductDetail/485-1956        |        |
| Optional Addon                                          |             |          |            |                 |                                                                   |                                                      |  $3.95 |
| Adafruit Mono 2.5W Class D Audio Amplifier - PAM8302    | 2130        | 1        | $3.95      | 1               | https://www.adafruit.com/product/2130                             | https://www.mouser.com/ProductDetail/485-2130        |        |


File: ./setup/introduction.mdx
---
title: Introduction
description: "The #1 open-source voice interface"
---

<img
  src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/banner.png"
/>

The **01** is an open-source platform for intelligent devices, inspired by the *Rabbit R1* and *Star Trek* computer.

Assistants powered by the 01 can execute code, browse the web, read and create files, control third-party software, and beyond.

<br></br>

<Card
  title="Install the 01"
  icon="arrow-right"
  href="/setup/installation"
  horizontal
></Card>

---

# Table of Contents

### Software

<CardGroup cols={2}>
  <Card title="Server" icon="server" href="/server">
    The brain of the 01 system that runs on your computer. It processes input, executes commands, generates responses, and manages core logic using Open Interpreter.
  </Card>
  <Card title="Client" icon="microphone" href="/client">
    The user interface that captures and transmits audio, plays back responses, and provides a seamless experience across various platforms.
  </Card>
</CardGroup>

### Hardware

<Card title="Build Options" icon="microchip" href="/hardware">
  Explore various hardware configurations, from desktop setups to ESP32-based portable builds and custom integrations. Find guides for assembling your own 01 device.
</Card>

File: ./setup/installation.mdx
---
title: "Installation"
---

## Prerequisites

To run the 01 on your computer, you will need to install the following essential packages:

- Git
- Python (version 3.11.x recommended)
- Poetry
- FFmpeg

<Tabs>
  <Tab title="MacOS">
    ### MacOS Installation

    1. **Git**: If you don't already have it, download and install Git from its [official website](https://git-scm.com/downloads).

    2. **Python**: 
       - Download **Python 3.11.x** from the [official Python website](https://www.python.org/downloads/).
       - During installation, make sure to check "Add Python to PATH".

    3. **Poetry**: 
       - Follow the [official Poetry installation guide](https://python-poetry.org/docs/#installing-with-the-official-installer).

    4. **FFmpeg and other dependencies**: 
       We recommend using Homebrew to install the required dependencies:

       ```bash
       brew install portaudio ffmpeg cmake
       ```

  </Tab>
  <Tab title="Windows">
    ### Windows Installation

    1. **Git**: Download and install [Git for Windows](https://git-scm.com/download/win).

    2. **Python**: 
       - Download Python 3.11.x from the [official Python website](https://www.python.org/downloads/windows/).
       - During installation, ensure you check "Add Python to PATH".

    3. **Microsoft C++ Build Tools**:
       - Download from [Microsoft's website](https://visualstudio.microsoft.com/visual-cpp-build-tools/).
       - Run the installer and select "Desktop development with C++" from the Workloads tab.
       - This step is crucial for Poetry to work correctly.

    4. **Poetry**:
       - If the standard installation method fails due to SSL issues, try this workaround:
         1. Download the installation script from [https://install.python-poetry.org/](https://install.python-poetry.org/) and save it as `install-poetry.py`.
         2. Open the file and replace the `get(self, url):` method with:
            ```python
            def get(self, url):
                import ssl
                import certifi
                request = Request(url, headers={"User-Agent": "Python Poetry"})
                context = ssl.create_default_context(cafile=certifi.where())
                context.check_hostname = False
                context.verify_mode = ssl.CERT_NONE
                with closing(urlopen(request, context=context)) as r:
                    return r.read()
            ```
         3. Run the modified script to install Poetry.
       - Add Poetry to your PATH:
         1. Press Win + R, type "sysdm.cpl", and press Enter.
         2. Go to the "Advanced" tab and click "Environment Variables".
         3. Under "User variables", find "Path" and click "Edit".
         4. Click "New" and add: `C:\Users\<USERNAME>\AppData\Roaming\Python\Scripts`
         5. Click "OK" to close all windows.

    5. **FFmpeg**:
       - Download the latest FFmpeg build from the [BtbN GitHub releases page](https://github.com/BtbN/FFmpeg-Builds/releases).
       - Choose the `ffmpeg-master-latest-win64-gpl.zip` (non-shared suffix) file.
       - Extract the compressed zip file.
       - Add the FFmpeg `bin` folder to your PATH:
         1. Press Win + R, type "sysdm.cpl", and press Enter.
         2. Go to the "Advanced" tab and click "Environment Variables".
         3. Under "System variables", find "Path" and click "Edit".
         4. Click "New" and add the full path to the FFmpeg `bin` folder (e.g., `C:\path\to\ffmpeg\bin`).
         5. Click "OK" to close all windows.

   ## Troubleshooting

   1. **Poetry Install Error**: If you encounter an error stating "Microsoft Visual C++ 14.0 or greater is required" when running `poetry install`, make sure you have properly installed the Microsoft C++ Build Tools as described in step 3 of the Windows installation guide.

   2. **FFmpeg Not Found**: If you receive an error saying FFmpeg is not found after installation, ensure that you've correctly added the FFmpeg `bin` folder to your system PATH as described in step 5 of the Windows installation guide.

   3. **Server Connection Issues**: If the server connects but you encounter errors when sending messages, double-check that all dependencies are correctly installed and that FFmpeg is properly set up in your PATH.

  </Tab>
  <Tab title="Linux">
    ### Linux Installation (Ubuntu)

    1. **Git**: If you don't already have it, install Git using:
       ```bash
       sudo apt-get update
       sudo apt-get install git
       ```

    2. **Python**: 
       - Install Python 3.11.x using:
         ```bash
         sudo apt-get install python3.11
         ```

    3. **Poetry**: 
       - Follow the [official Poetry installation guide](https://python-poetry.org/docs/#installing-with-the-official-installer).

    4. **FFmpeg and other dependencies**: 
       Install the required packages:

       ```bash
       sudo apt-get update
       sudo apt-get install portaudio19-dev ffmpeg cmake
       ```

  </Tab>
</Tabs>

## Install 01

Now, clone the repo and navigate into the 01 directory:

```bash
git clone https://github.com/OpenInterpreter/01.git
cd 01
```

Then, navigate to the project's software directory:

```bash
cd software
```

**Your current working directory should now be `01/software`.**

Finally, install the project's dependencies in a virtual environment managed by Poetry.

```bash
poetry install
```

Now you should be ready to [run the 01](/server/).

First, we recommend you familiarize yourself with our [safety report](/safety/).

File: ./server/livekit.mdx
---
title: "Livekit Server"
description: "A robust, feature-rich voice server for your 01"
---

## Overview

[Livekit](https://livekit.io/) is a powerful, open-source WebRTC server and client SDK that enables real-time audio communication. It's designed for applications that require robust, scalable real-time features.

### Key Features

- Scalable architecture
- Extensive documentation and community support
- SDKs for various languages and platforms (web, mobile, desktop)

## Getting Started

### Prerequisites

Make sure you have navigated to the `software` directory before proceeding.

### Installing Livekit

Before setting up the environment, you need to install Livekit. Follow the instructions for your operating system:

- **macOS**:

  ```bash
  brew install livekit
  ```

- **Linux**:

  ```bash
  curl -sSL https://get.livekit.io | bash
  ```

- **Windows**:
  [View the Windows install instructions here.](/server/windows-livekit)

### Environment Setup

1. Create a `.env` file in the `/software` directory with the following content:

```env
ELEVEN_API_KEY=your_eleven_labs_api_key
DEEPGRAM_API_KEY=your_deepgram_api_key
NGROK_AUTHTOKEN=your_ngrok_auth_token
ANTHROPIC_API_KEY=your_anthropic_api_key
```

Replace the placeholders with your actual API keys.

<CardGroup cols={3}>
  <Card title="Eleven Labs" icon="microphone" href="https://beta.elevenlabs.io">
    Get your Eleven Labs API key for text-to-speech
  </Card>
  <Card
    title="Deepgram"
    icon="waveform-lines"
    href="https://console.deepgram.com"
  >
    Obtain your Deepgram API key for speech recognition
  </Card>
  <Card title="Ngrok" icon="wifi" href="https://dashboard.ngrok.com">
    Sign up for Ngrok and get your auth token
  </Card>
</CardGroup>

### Starting the Server

To start the Livekit server, run the following command:

```bash
poetry run 01 --server livekit
```

To generate a QR code for scanning

```bash
poetry run 01 --server livekit --qr
```

To expose over the internet via ngrok

```bash
poetry run 01 --server livekit --expose
```

In order to use the mobile app over the web, use both flags

```bash
poetry run 01 --server livekit --qr --expose
```

<Note>
  Currently, our Livekit server only works with Deepgram and Eleven Labs. We are
  working to introduce all-local functionality as soon as possible. By setting
  your profile (see [Configure Your Profile](/software/configure)), you can
  still change your LLM to be a local LLM, but the `interpreter.tts` value will
  be ignored for the Livekit server.
</Note>

## Livekit vs. Light Server

- **Livekit Server**: Designed for devices with higher processing power, such as phones, web browsers, and more capable hardware. It offers a full range of features and robust performance.

- **Light Server**: We have another lightweight server called the Light server, specifically designed for ESP32 devices. It's optimized for low-power, constrained environments.

## SDK Integration

Livekit provides SDKs for various programming languages and platforms, allowing you to easily integrate real-time communication features into your applications.

### Available SDKs

- JavaScript/TypeScript
- React
- React Native
- iOS (Swift)
- Android (Kotlin)
- Flutter
- Unity

<Card
  title="Explore Livekit SDKs"
  icon="code"
  href="https://docs.livekit.io/client-sdk-js/"
>
  Find documentation and integration guides for all Livekit SDKs.
</Card>


File: ./server/windows-livekit.mdx
# LiveKit Installation Guide for Windows

## Required Software

- Git
- Python (version 3.11.9 recommended)
- Poetry (Python package manager)
- LiveKit server for Windows
- FFmpeg

## Installation Steps

### 1. Python Installation

Install Python 3.11.9 (latest version < 3.12) using the binary installer.

### 2. Poetry Installation

Poetry installation on Windows can be challenging. If you encounter SSL certificate verification issues, try this workaround:

1. Download the installation script from [https://install.python-poetry.org/](https://install.python-poetry.org/) and save it as `install-poetry.py`.
2. Modify the `get(self, url):` method in the script to disable certificate verification:

   ```python
   def get(self, url):
       import ssl
       import certifi
       request = Request(url)
       context = ssl.create_default_context(cafile=certifi.where())
       context.check_hostname = False
       context.verify_mode = ssl.CERT_NONE
       with closing(urlopen(request, context=context)) as r:
           return r.read()
   ```

3. Run the modified script to install Poetry.
4. Add Poetry's bin directory to your PATH:
   - Path: `C:\Users\[USERNAME]\AppData\Roaming\Python\Scripts`
   - Follow the guide at: [https://www.java.com/en/download/help/path.html](https://www.java.com/en/download/help/path.html)

### 3. LiveKit Server Installation

1. Download the latest release of LiveKit server for Windows (e.g., `livekit_1.7.2_windows_amd64.zip`).
2. Extract the `livekit-server.exe` file to your `/software` directory.

### 4. FFmpeg Installation

1. Download the FFmpeg Windows build from: [https://github.com/BtbN/FFmpeg-Builds/releases](https://github.com/BtbN/FFmpeg-Builds/releases)
   - Choose the `ffmpeg-master-latest-win64-gpl.zip` (non-shared suffix) version.
2. Extract the compressed zip and add the FFmpeg bin directory to your PATH.

### 5. Final Setup

1. Run `poetry install`. If you encounter an error about Microsoft Visual C++, install "Microsoft C++ Build Tools":
   - Download from: [https://visualstudio.microsoft.com/visual-cpp-build-tools/](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
   - In the installation popup, select "Desktop Development with C++" with preselected components.

2. Set up your Anthropic API key:
   ```
   setx ANTHROPIC_API_KEY [your_api_key]
   ```

3. Modify `main.py` to correctly locate and run the LiveKit server:
   - Set the LiveKit path:
     ```python
     livekit_path = "path/to/your/01/software/livekit-server"
     ```
   - Modify the server command for Windows:
     ```python
     f"{livekit_path} --dev --bind {server_host} --port {server_port}"
     ```
   > Note: Remove the `> /dev/null 2>&1` section from the command as it's not compatible with Windows.

## Troubleshooting

- If you encounter "ffmpeg not found" errors or issues when sending messages, ensure FFmpeg is correctly installed and added to your PATH.
- For any SSL certificate issues during installation, refer to the Poetry installation workaround provided above.

File: ./server/introduction.mdx
---
title: "Introduction"
---



The 01 project supports two different server types to accommodate various hardware capabilities and use cases.

## Server Options

<CardGroup cols={2}>
  <Card title="Light Server" icon="microchip" href="/server/light">
    Optimized for low-power, constrained environments like ESP32 devices.
  </Card>
  <Card title="Livekit Server" icon="server" href="/server/livekit">
    Full-featured server for devices with higher processing power, such as phones, web browsers, and desktop computers.
  </Card>
</CardGroup>

### Choosing the Right Server

- **Light Server**: Ideal for embedded systems and IoT devices with limited resources.
- **Livekit Server**: Offers robust performance and a full range of features for more capable hardware.

Select the server that best fits your device and project requirements.

File: ./server/flags.mdx
---
title: "Flags"
description: "Customize the behaviour of your 01 from the CLI"
---

## CLI Flags

### Server

Specify the server to run.

Valid arguments are either [livekit](/server/livekit) or [light](/server/light)

```
poetry run 01 --server light
```

### Server Host

Specify the server host where the server will deploy.

Default: `0.0.0.0`.

```
poetry run 01 --server-host 0.0.0.0
```

### Server Port

Specify the server port where the server will deploy.

Default: `10001`.

```
poetry run 01 --server-port 10001
```

### Expose

Expose server to internet.

```
poetry run 01 --expose
```

### Client

Specify the client.

Valid argument is `light-python`

```
poetry run 01 --client light-python
```

### Server URL

Specify the server URL that the client should expect.
Defaults sets the server-host and server-port.

Default: `None`.

```
poetry run 01 --server-url http://0.0.0.0:10001
```

### QR

Display QR code to scan to connect to the server.

```
poetry run 01 --qr
```

### Help

Show this message and exit.

```
poetry run 01 --help
```


File: ./server/configure.mdx
---
title: "Configure"
description: "Configure your 01 instance"
---

A core part of the 01 server is the interpreter which is an instance of Open Interpreter.
Open Interpreter is highly configurable and only requires updating or creating a profile.
Properties such as `model`, `context_window`, and many more can be updated here.

To open the directory of all profiles, run:

```bash
# View profiles
poetry run 01 --profiles
```

To apply a profile to your 01 instance, use the `--profile` flag followed by the name of the profile:

```bash
# Use profile
poetry run 01 --profile <profile_name>
```

### Standard Profiles

`default.py` is the default profile that is used when no profile is specified. The default TTS is OpenAI.

`fast.py` uses elevenlabs and groq, which are the fastest providers.

`local.py` uses coqui TTS and runs the --local explorer from Open Interpreter.

### Custom Profiles

If you want to make your own file, you can do so by creating a new file in the `profiles` directory.
The easiest way is to duplicate an existing profile and then update values as needed. Be sure to save the profile with a unique name.

Remember to add `interpreter.tts = ` to set the text-to-speech provider.

To use a custom profile, run:

```bash
# Use custom profile
poetry run 01 --profile <profile_name>
```

### Example Profile

````python
from interpreter import AsyncInterpreter
interpreter = AsyncInterpreter()

# This is an Open Interpreter compatible profile.
# Visit https://01.openinterpreter.com/profile for all options.

# 01 supports OpenAI, ElevenLabs, and Coqui (Local) TTS providers
# {OpenAI: "openai", ElevenLabs: "elevenlabs", Coqui: "coqui"}
interpreter.tts = "openai"

# Connect your 01 to a language model
interpreter.llm.model = "gpt-4o"
interpreter.llm.context_window = 100000
interpreter.llm.max_tokens = 4096
# interpreter.llm.api_key = "<your_openai_api_key_here>"

# Tell your 01 where to find and save skills
interpreter.computer.skills.path = "./skills"

# Extra settings
interpreter.computer.import_computer_api = True
interpreter.computer.import_skills = True
interpreter.computer.run("python", "computer")  # This will trigger those imports
interpreter.auto_run = True
interpreter.loop = True
interpreter.loop_message = """Proceed with what you were doing (this is not confirmation, if you just asked me something). You CAN run code on my machine. If you want to run code, start your message with "```"! If the entire task is done, say exactly 'The task is done.' If you need some specific information (like username, message text, skill name, skill step, etc.) say EXACTLY 'Please provide more information.' If it's impossible, say 'The task is impossible.' (If I haven't provided a task, say exactly 'Let me know what you'd like to do next.') Otherwise keep going. CRITICAL: REMEMBER TO FOLLOW ALL PREVIOUS INSTRUCTIONS. If I'm teaching you something, remember to run the related `computer.skills.new_skill` function."""
interpreter.loop_breakers = [
    "The task is done.",
    "The task is impossible.",
    "Let me know what you'd like to do next.",
    "Please provide more information.",
]

# Set the identity and personality of your 01
interpreter.system_message = """

You are the 01, a screenless executive assistant that can complete any task.
When you execute code, it will be executed on the user's machine. The user has given you full and complete permission to execute any code necessary to complete the task.
Run any code to achieve the goal, and if at first you don't succeed, try again and again.
You can install new packages.
Be concise. Your messages are being read aloud to the user. DO NOT MAKE PLANS. RUN CODE QUICKLY.
Try to spread complex tasks over multiple code blocks. Don't try to complex tasks in one go.
Manually summarize text."""
````

### Hosted LLMs

The default LLM for 01 is GPT-4-Turbo. You can find this in the default profile in `software/source/server/profiles/default.py`.

The fast profile uses Llama3-8b served by Groq. You can find this in the fast profile in `software/source/server/profiles/fast.py`.

```python
# Set your profile with a hosted LLM
interpreter.llm.model = "gpt-4o"
```

### Local LLMs

You can use local models to power 01.

Using the local profile launches the Local Explorer where you can select your inference provider and model. The default options include Llamafile, Jan, Ollama, and LM Studio.

```python
# Set your profile with a local LLM
interpreter.llm.model = "ollama/codestral"

# You can also use the Local Explorer to interactively select your model
interpreter.local_setup()
```

### Hosted TTS

01 supports OpenAI and Elevenlabs for hosted TTS.

```python
# Set your profile with a hosted TTS service
interpreter.tts = "elevenlabs"
```

### Local TTS

For local TTS, Coqui is used.

```python
# Set your profile with a local TTS service
interpreter.tts = "coqui"
```

<Note>
  When using the Livekit server, the interpreter.tts setting in your profile
  will be ignored. The Livekit server currently only works with Deepgram for
  speech recognition and Eleven Labs for text-to-speech. We are working on
  introducing all-local functionality for the Livekit server as soon as
  possible.
</Note>


File: ./server/installation.mdx
---
title: "Install"
description: "Get your 01 up and running"
---

## Install 01

To install the 01 software:

```bash
# Clone the repo and navigate into the 01 directory
git clone https://github.com/OpenInterpreter/01.git
cd 01
```

## Run the 01

Navigate to the project's software directory:

```bash
cd software
```

Install your project along with its dependencies in a virtual environment managed by Poetry.

```bash
poetry install
```

Now you should be ready to [run your 01](/software/server/introduction).


File: ./server/light.mdx
---
title: "Light Server"
description: "A lightweight voice server for your 01"
---

## Overview

The Light server streams bytes of audio to an ESP32 and the Light Python client.

### Key Features

- Lightweight
- Works with ESP32
- Can use local options for Speech-to-Text and Text-to-Speech

## Getting Started

### Prerequisites

Make sure you have navigated to the `software` directory before proceeding.

### Starting the Server

To start the Light server, run the following command:

```bash
poetry run 01 --server light
```


File: ./troubleshooting/faq.mdx
---
title: "FAQ"
description: "Frequently Asked Questions"
---

<Accordion title="Where should I start?">
  We have a [Getting Started](/getting-started/getting-started) guide that will
  help you get up and running with the 01.
</Accordion>

<Accordion title="Is there a walk-through for connecting a device to the server?">
  We have a [Connecting](/software/connecting-a-device) guide that will help you
  get up and running with the 01.
</Accordion>

<Accordion title="How do I have code run on the client-side?">
  We are working on supporting this, but we only support server-side code
  execution right now.
</Accordion>

<Accordion title="How do I build a profile?">
  We recommend running `--profiles`, duplicating a profile, then experimenting
  with the settings in the profile file (like `system_message`).
</Accordion>

<Accordion title="Where does the server run?">
  The server runs on your home computer, or whichever device you want to
  control.
</Accordion>

<Accordion title="My app is stuck on the 'Starting...' screen. What do I do?">
  You might need to re-install the Poetry environment. In the `software`
  directory, please run `poetry env remove --all` followed by `poetry install`
</Accordion>

<Accordion title="Can an 01 device connect to the desktop app, or do general customers/consumers need to set it up in their terminal?">
  We are working on supporting external devices to the desktop app, but for now
  the 01 will need to connect to the Python server.
</Accordion>

<Accordion title="Can I on/off certain tools?">
  We are working on building this feature, but it isn't avaliable yet.
</Accordion>

<Accordion title="Alternatives to nGrok?">
  We support `--tunnel-service bore` and `--tunnel-service localtunnel` in
  addition to `--tunnel-service ngrok`. [link to tunnel service docs]
</Accordion>

<Accordion title="Uses a huge deal of API credits, what options do I have for using local models? Can these be run on the client device?">
  If you use `--profile local`, you won't need to use an LLM via an API. The 01
  server will be responsible for LLM running, but you can run the server +
  client on the same device (simply run `poetry run 01` to test this.)
</Accordion>

<Accordion title="Which model is best?">
  We have found `gpt-4-turbo` to be the best, but we expect Claude Sonnet 1.5 to
  be comparable or better.
</Accordion>

<Accordion title="Do I need to pay for a monthly subscription?">
  If you use `--profile local`, you don't need to. For hosted language models,
  you may need to pay a monthly subscription.
</Accordion>

<Accordion title="Does the computer the O1 connects to need to always be on and running? If its in sleep mode will it wake up when I call on it?">
  The computer does need to be running, and will not wake up if a request is
  sent while it's sleeping.
</Accordion>

<Accordion title="Which Model does 01 use?">
  The 01 defaults to `gpt-4-turbo`.
</Accordion>

<Accordion title="Do you support a Standalone Device/Hosted Server?">
  We are exploring a few options about how to best provide a stand-alone device
  connected to a virtual computer in the cloud, provided by Open Interpreter.
  There will be an announcement once we have figured out the right way to do it.
  But the idea is that it functions with the same capabilities as the demo, just
  controlling a computer in the cloud, not the one on your desk at home.
</Accordion>

<Accordion title="How Do I Get Involved?">
  We are figuring out the best way to activate the community to build the next
  phase. For now, you can read over the Repository
  https://github.com/OpenInterpreter/01 and join the Discord
  https://discord.gg/Hvz9Axh84z to find and discuss ways to start contributing
  to the open-source 01 Project!
</Accordion>

<Accordion title="Is there a Mobile App?">
  The official app is being developed, and you can find instructions for how to
  set it up and contribute to development here:
  https://github.com/OpenInterpreter/01/tree/main/software/source/clients/mobile
  Please also join the Discord https://discord.gg/Hvz9Axh84z to find and discuss
  ways to start contributing to the open-source 01 Project!
</Accordion>

<Accordion title="Are there any third parties involved in the communication between 01 and my computer?">
  If you use ngrok when running `--expose` on the [01
  Repo](https://github.com/OpenInterpreter/01), that is the only third party
  involved. You can also use bore and localtunnel — these are used to expose
  your 01 server over the internet for your device to connect to. If you run it
  locally, and connect to the server via something like 0.0.0.0, no third
  parties are involved.
</Accordion>

<Accordion title="Is communication between 01 and my computer end-to-end encrypted and if so what is the encryption standard used?">
  This depends on which api_base / llm service provider you use, but re the
  recommended gpt models: "OpenAI encrypts all data at rest (AES-256) and in
  transit (TLS 1.2+)". This will be different for Anthropic, Ollama, etc. but
  I'd expect all large providers to have the same encryption standards.
</Accordion>

File: ./safety/measures.mdx
---
title: "Measures"
description: "Essential steps to protect yourself when using 01"
---

**The 01 requires a proactive approach to safety.**

This section provides essential measures to protect your system and data when using the 01. Each measure is accompanied by specific tool recommendations to help you implement these safety practices effectively.

By following these guidelines, you can *somewhat* minimize risks and use the 01 with greater confidence— but **the 01 is nonetheless an experimental technology that may not be suitable for everyone.**

## 1. Comprehensive Backups

Before using the 01, ensure you have robust, up-to-date backups:

- Use reliable backup software to create full system images:
  - For Windows: [Macrium Reflect Free](https://www.macrium.com/reflectfree)
  - For macOS: Time Machine (built-in) or [Carbon Copy Cloner](https://bombich.com/)
  - For Linux: [Clonezilla](https://clonezilla.org/)
- Store backups on external drives or trusted cloud services like [Backblaze](https://www.backblaze.com/) or [iDrive](https://www.idrive.com/).
- Regularly test your backups to ensure they can be restored.
- Keep at least one backup offline and disconnected from your network.

Remember: A good backup is your last line of defense against unintended changes or data loss.

## 2. Use a Dedicated Environment

Isolate the 01 to minimize potential damage:

- Run the 01 in a virtual machine if possible. [VirtualBox](https://www.virtualbox.org/) is a free, cross-platform option.
- If not, create a separate user account with limited permissions for 01 use.
- Consider using a separate, non-essential device for 01 experiments.

## 3. Network Isolation

Limit the 01's ability to affect your network:

- Use a firewall to restrict the 01's network access. Windows and macOS have built-in firewalls; for Linux, consider [UFW](https://help.ubuntu.com/community/UFW).
- Consider running the 01 behind a VPN for an additional layer of isolation. [ProtonVPN](https://protonvpn.com/) offers a free tier.
- Disable unnecessary network services when using the 01.

## 4. Vigilant Monitoring

Stay alert during 01 usage:

- Pay close attention to the 01's actions and your system's behavior.
- Be prepared to quickly terminate the 01 if you notice anything suspicious.
- Regularly check system logs and monitor for unexpected changes.

## 5. Careful Command Formulation

Be precise and cautious with your voice commands:

- Start with simple, specific tasks before attempting complex operations.
- Avoid ambiguous language that could be misinterpreted.
- When possible, specify limitations or constraints in your commands.

## 6. Regular System Audits

Periodically check your system's integrity:

- Review important files and settings after using the 01.
- Use system comparison tools to identify changes made during 01 sessions:
  - For Windows: [WinMerge](https://winmerge.org/)
  - For macOS/Linux: [Meld](https://meldmerge.org/)
- Promptly investigate and address any unexpected modifications.

## 7. Stay Informed

Keep up with 01 developments:

- Regularly check for updates to the 01 software.
- Stay informed about newly discovered risks or vulnerabilities.
- Follow best practices shared by the 01 developer community.

By following these measures, you can significantly reduce the risks associated with using the 01. Remember, your active involvement in maintaining safety is crucial when working with this powerful, experimental technology.

File: ./safety/introduction.mdx
---
title: "Introduction"
description: "Critical safety information for 01 users"
---

<Warning>This experimental project is under rapid development and lacks basic safeguards. Until a stable `1.0` release, **only run the 01 on devices without access to sensitive information.**</Warning>

The 01 is an experimental voice assistant that can execute code based on voice commands. This power comes with significant risks that all users must understand.

<CardGroup cols={2}>
  <Card title="Key Risks" href="/safety/risks">
    Understand the dangers
  </Card>
  <Card title="Safety Measures" href="/safety/measures">
    Protect yourself and your system
  </Card>
</CardGroup>

## Why Safety Matters

The 01 directly interacts with your system, executing code without showing it to you first. This means:

1. It can make changes to your files and system settings instantly.
2. Misinterpretations of your commands can lead to unintended actions.
3. The AI may not fully understand the context or implications of its actions.

Always approach using the 01 with caution. It's not your usual voice assistant – **the 01 is a powerful tool that can alter your digital environment in seconds.**

<Warning>Remember: The 01 is experimental technology. Your safety depends on your understanding of its capabilities and limitations.</Warning>

File: ./safety/risks.mdx
---
title: "Risks"
description: "Understanding the dangers of using 01"
---

The 01 voice assistant offers powerful control over your digital environment through natural language commands. 

However, this capability comes with **significant risks.** Understanding these risks is crucial for safe and responsible use of the 01.

This section outlines the key dangers associated with the 01's ability to execute code instantly based on voice input. Being aware of these risks is the first step in using the 01 effectively and safely.

## Immediate Code Execution

The 01 executes code directly based on voice commands, without showing you the code first. This means:

- Actions are taken instantly, giving you no chance to review or stop them.
- Misinterpretations of your commands can lead to immediate, unintended consequences.
- Complex or ambiguous requests might result in unexpected system changes.

## System and Data Vulnerability

Your entire system is potentially accessible to the 01, including:

- Important files and documents
- System settings and configurations
- Personal and sensitive information

A misinterpreted command could lead to data loss, system misconfiguration, or privacy breaches.

## Prompt Injection Vulnerability

The 01 processes text from various sources, making it susceptible to prompt injection attacks:

- Malicious instructions could be hidden in emails, documents, or websites.
- If the 01 processes this text, it might execute harmful commands without your knowledge.
- This could lead to unauthorized actions, data theft, or system compromise.

## Lack of Context Understanding

While powerful, the 01's AI may not fully grasp the broader context of your digital environment:

- It might not understand the importance of certain files or settings.
- The AI could make changes that conflict with other software or system requirements.
- Long-term consequences of actions might not be apparent to the AI.

## Experimental Nature

Remember, the 01 is cutting-edge, experimental technology:

- Unexpected behaviors or bugs may occur.
- The full extent of potential risks is not yet known.
- Safety measures may not cover all possible scenarios.

Understanding these risks is crucial for safe use of the 01. Always err on the side of caution, especially when dealing with important data or system configurations.

File: ./logo/Z-icon-white.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./logo/Z.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./logo/Z-icon-black.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./video_documentation/collection.md

## For End Users
[Announcment video](https://www.youtube.com/watch?v=jWr-WeXAdeI)
[Wes Roth](https://www.youtube.com/@WesRoth)

<details>
<summary>Details</summary>

No technical coverage

</details>

---

[Announcment video](https://www.youtube.com/watch?v=JaBFT3fF2fk)
[TheAIGRID](https://www.youtube.com/@TheAiGrid)

<details>
<summary>Details</summary>

[here](https://youtu.be/JaBFT3fF2fk?si=8zPGO-U6WdLNnISw&t=656)
mentions the current lack of windows support

</details>

---

[Announcment video](https://www.youtube.com/watch?v=Q_p82HtBqoc)
[Matt Berman](https://www.youtube.com/@matthew_berman)

<details>
<summary>Details</summary>

[here](https://youtu.be/Q_p82HtBqoc?si=aAxjWZnBdwBbaOUr&t=579)
Berman shows an install of 01 using conda and python 3.9
in.. looks like linux.. shows how to get openai keys.

</details>

---

[Announcment video](https://www.youtube.com/watch?v=q0dJ7T7au2Y)
[WorldofAI](https://www.youtube.com/@intheworldofai)

<details>
<summary>Details</summary>

<!-- Add details here -->

</details>

---

[Breakdown video](https://www.youtube.com/watch?v=W-VwN0n4d9Y)
[Mervin Praison](https://www.youtube.com/@MervinPraison)
<details>
<summary>Details</summary>
- uses conda to install 01 and uses python 3.11 on linux.. maybe mac
- 0:00 Introduction to Open Interpreter
- 0:47 Creating Apps and Summarizing Documents
- 1:20 Image Modifications and Game Creation
- 2:55 Exploratory Data Analysis and Charting
- 4:00 Server Log Analysis
- 5:01 Image and Video Editing
- 6:00 Composing Music with AI
- 7:18 Calendar Management and Email Automation
- 9:01 Integrating with Fast API and LM Studio

</details>

---

[Breakdown video](https://www.youtube.com/watch?v=uyfoHQVgeY0)
[Gary Explains](https://www.youtube.com/@GaryExplains)
<br>for **open interpreter** not **01**
<details>
<summary>Details</summary>
- 3:45 states that it will run on mac/linux and windows and requires python 3.10
</details>

## For Developers
<BR>
Coming soon

File: ./legal/terms-of-service.mdx
---
title: "Terms of Service"
description: "Understand your rights and responsibilities when using the 01 App."
---

<CardGroup cols={2}>
  <Card
    title="Privacy Policy"
    icon="shield-check"
    href="/legal/privacy-policy"
  >
    Understand how we collect, use, and protect your data.
  </Card>

  <Card
    title="Terms of Service"
    icon="file-contract"
    href="/legal/terms-of-service"
  >
    Understand your rights and responsibilities when using the 01 App.
  </Card>
</CardGroup>


# Terms of Service

Last Updated: September 11, 2024

## 1. Acceptance of Terms

By using the 01 App ("the App"), you agree to be bound by these Terms of Service. If you do not agree to these terms, do not use the App.

## 2. Description of Service

The 01 App is an experimental artificial intelligence chat application that has the capability to execute code on your computer. By using this App, you acknowledge and accept that:

- The App can control your computer
- The App is capable of damaging your system
- The App may perform actions that could be considered malicious

## 3. User Responsibilities

Before using the App, you must:

- Back up all your files
- Understand the safety implications of running AI-generated code on your computer
- Read and agree to these terms and conditions

## 4. Risks and Disclaimer

You understand and agree that:

- The App is experimental and may cause damage to your system
- You use the App at your own risk
- We are not responsible for any damage, data loss, or other negative consequences resulting from your use of the App

## 5. Indemnification

You agree to indemnify and hold harmless the App developers, owners, and affiliates from any claims, damages, or expenses arising from your use of the App.

## 6. Modifications to Service

We reserve the right to modify or discontinue the App at any time without notice.

## 7. Governing Law

These terms shall be governed by and construed in accordance with the laws of Washington, USA.

## 8. Contact Information

For questions about these Terms, please contact us at: help@openinterpreter.com

By using the 01 App, you acknowledge that you have read, understood, and agree to be bound by these Terms of Service.

File: ./legal/privacy-policy.mdx
---
title: "Privacy Policy"
description: "Understand how we collect, use, and protect your data."
---

<CardGroup cols={2}>
  <Card
    title="Privacy Policy"
    icon="shield-check"
    href="/legal/privacy-policy"
  >
    Understand how we collect, use, and protect your data.
  </Card>

  <Card
    title="Terms of Service"
    icon="file-contract"
    href="/legal/terms-of-service"
  >
    Understand your rights and responsibilities when using the 01 App.
  </Card>
</CardGroup>

# Privacy Policy

Last updated: August 8th, 2024

## 1. Introduction

Welcome to the 01 App. We are committed to protecting your privacy and providing a safe, AI-powered chat experience. This Privacy Policy explains how we collect, use, and protect your information when you use our app.

## 2. Information We Collect

### 2.1 When Using Our Cloud Service

If you choose to use our cloud service, we collect and store:

- Your email address
- Transcriptions of your interactions with our AI assistant
- Any images you send to or receive from the AI assistant

### 2.2 When Using Self-Hosted Server

If you connect to your own self-hosted server, we do not collect or store any of your data, including your email address.

## 3. How We Use Your Information

We use the collected information solely for the purpose of providing and improving our AI chat service. This includes:

- Facilitating communication between you and our AI assistant
- Improving the accuracy and relevance of AI responses
- Analyzing usage patterns to enhance user experience

## 4. Data Storage and Security

We take appropriate measures to protect your data from unauthorized access, alteration, or destruction. All data is stored securely and accessed only by authorized personnel.

## 5. Data Sharing and Third-Party Services

We do not sell, trade, or otherwise transfer your personally identifiable information to outside parties. This does not include trusted third parties who assist us in operating our app, conducting our business, or servicing you, as long as those parties agree to keep this information confidential.

We may use third-party services for analytics and app functionality. These services may collect anonymous usage data to help us improve the app.

## 6. Data Retention and Deletion

We retain your data for as long as your account is active or as needed to provide you services. If you wish to cancel your account or request that we no longer use your information, please contact us using the information in Section 11.

## 7. Your Rights

You have the right to:

- Access the personal information we hold about you
- Request correction of any inaccurate information
- Request deletion of your data from our systems

To exercise these rights, please contact us using the information provided in Section 11.

## 8. Children's Privacy

Our app is not intended for children under the age of 13. We do not knowingly collect personal information from children under 13. If you are a parent or guardian and you are aware that your child has provided us with personal information, please contact us.

## 9. International Data Transfer

Your information, including personal data, may be transferred to — and maintained on — computers located outside of your state, province, country or other governmental jurisdiction where the data protection laws may differ from those in your jurisdiction.

## 10. Changes to This Privacy Policy

We may update our Privacy Policy from time to time. We will notify you of any changes by posting the new Privacy Policy on this page and updating the "Last updated" date.

## 11. Contact Us

If you have any questions about this Privacy Policy, please contact us at:

Email: help@openinterpreter.com

## 12. California Privacy Rights

If you are a California resident, you have the right to request information regarding the disclosure of your personal information to third parties for direct marketing purposes, and to opt-out of such disclosures. As stated in this Privacy Policy, we do not share your personal information with third parties for direct marketing purposes.

## 13. Cookies and Tracking

Our app does not use cookies or web tracking technologies.

## 14. Consent

By using the 01 App, you consent to this Privacy Policy.



File: ./assets/copy-client.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/ESPAsyncWebServer-install-all.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/M5-atom-library.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/AsyncTCP by dvarrel.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/app.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/paste-client.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/banner.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/pasted-client.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/m5atomecho.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/connect_usb.jpeg
'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

File: ./assets/boards-manager.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/hardcode-wifi-pass-server.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/ESPAsyncWebServer by lacamera.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/Upload.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/01-light.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/WebSockets by Markus Sattler.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/Select Board and Port.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./assets/m5-atom-install-all.png
'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

File: ./client/esp32.mdx
---
title: "ESP32"
description: "How to setup the ESP32"
---

<Info>This client uses the [light](/server/light) server.</Info>

### Video Guide

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/Y76zed8nEE8"
  frameBorder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
></iframe>

---

To set up the ESP32 for use with 01, follow this guide to install the firmware:

<Steps>
  <Step title="Download Arduino IDE">
    <Card title="Download Arduino IDE" icon="download" href="https://www.arduino.cc/en/software">
      Get the Arduino IDE
    </Card>
  </Step>

  <Step title="Get the firmware">
    Get the firmware by copying the contents of [client.ino](https://github.com/OpenInterpreter/01/blob/main/software/source/clients/esp32/src/client/client.ino) from the 01 repository.

    <Card title="View client.ino" icon="code" href="https://github.com/OpenInterpreter/01/blob/main/software/source/clients/esp32/src/client/client.ino">
      View the ESP32 firmware source code
    </Card>

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/copy-client.png" alt="Copy client.ino contents" width="80%" />
  </Step>

  <Step title="Paste firmware into Arduino IDE">
    Open Arduino IDE and paste the client.ino contents.

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/paste-client.png" alt="Paste client.ino contents" width="80%" />

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/pasted-client.png" alt="Pasted client.ino contents" width="80%" />
  </Step>

  <Step title="(Optional) Hardcode credentials">
    Hardcode your WiFi SSID, WiFi password, and server URL into the top of the `client.ino` file.

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/hardcode-wifi-pass-server.png" alt="Hardcode WiFi SSID and password" width="80%" />

    Hardcoding is recommended for a more streamlined setup and development environment. However, if you don't hardcode these values or if the ESP32 can't connect using the provided information, it will automatically default to a captive portal for configuration. 
  </Step>

  <Step title="Install ESP32 boards">
    Go to Tools -> Board -> Boards Manager, search "esp32", then install the boards by Arduino and Espressif.

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/boards-manager.png" alt="Install ESP32 boards" width="80%" />
  </Step>

  <Step title="Install required libraries">
    Go to Tools -> Manage Libraries, then install the following:

    - M5Atom by M5Stack ([Reference](https://www.arduino.cc/reference/en/libraries/m5atom/))

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/M5-atom-library.png" alt="Install M5Atom library" width="80%" />

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/m5-atom-install-all.png" alt="Install all M5Atom dependencies" width="80%" />

    - WebSockets by Markus Sattler ([Reference](https://www.arduino.cc/reference/en/libraries/websockets/))

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/WebSockets by Markus Sattler.png" alt="Install WebSockets library" width="80%" />

    - AsyncTCP by dvarrel ([Reference](https://github.com/dvarrel/AsyncTCP))

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/AsyncTCP by dvarrel.png" alt="Install AsyncTCP library" width="80%" />

    - ESPAsyncWebServer by lacamera ([Reference](https://github.com/lacamera/ESPAsyncWebServer))

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/ESPAsyncWebServer by lacamera.png" alt="Install ESPAsyncWebServer library" width="80%" />

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/ESPAsyncWebServer-install-all.png" alt="Install all ESPAsyncWebServer dependencies" width="80%" />
  </Step>

  <Step title="Connect the board">
    To flash the .ino to the board, connect the board to the USB port.

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/connect_usb.jpeg" alt="Connect USB" width="80%" />
  </Step>

  <Step title="Select board and port">
    Select the port from the dropdown on the IDE, then select the M5Atom board (or M5Stack-ATOM if you have that).

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/Select Board and Port.png" alt="Select Board and Port" width="80%" />
  </Step>

  <Step title="Upload firmware">
    Click on upload to flash the board.

    <img src="https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/Upload.png" alt="Upload firmware" width="80%" />
  </Step>

  <Step title="Start the 01 server">
    Start the 01 server on your computer:
    ```
    poetry run 01 --server light
    ```
    This command starts the server and generates a URL.

    For remote connections, use:
    ```
    poetry run 01 --server light --expose
    ```
    This generates a public URL accessible from anywhere.
  </Step>

  <Step title="Connect ESP32 to the server">
    Connect your 01 device to the server using one of these methods:

    a) Hardcode credentials:
    - Modify the Wi-Fi and server credentials at the top of the `client.ino` file.
    - Flash the modified file to the ESP32.
    - This method is quick but less flexible for changing details later.

    b) Use the captive portal:
    - Power on your 01 device.
    - Connect to the '01-light' Wi-Fi network from your computer or smartphone.
    - A captive portal page should open automatically. If not, open a web browser.
    - Enter your Wi-Fi details and the server URL from step 1.
    - Click 'Connect' to save settings and connect your device.

    After successful connection, your ESP32 will be ready to communicate with the server.
  </Step>
</Steps>


File: ./client/android-ios.mdx
---
title: "Android & iOS"
description: "A react-native client for the 01"
---

<CardGroup cols={3}>
  <Card title="Source Code" icon="github" href="https://github.com/OpenInterpreter/01-app">
    View on GitHub
  </Card>
  <Card title="Android" icon="android" href="https://play.google.com/store/apps/details?id=com.interpreter.app">
    Get it on Google Play
  </Card>
  <Card title="iOS" icon="apple" href="https://apps.apple.com/ca/app/01-light/id6601937732">
    Download on the App Store
  </Card>
</CardGroup>

![A mini Android phone running the 01 App](https://raw.githubusercontent.com/OpenInterpreter/01/main/docs/assets/app.png)

The 01 App connects to the 01 server on your home machine, enabling remote access to your files, apps, and IoT devices.

# Setup

<Steps>
  <Step title="Install 01">
    Install the 01 software on your computer. For detailed instructions, visit the [installation guide](/setup/installation).
  </Step>
  <Step title="Install Livekit">
    Setup Livekit on your computer. For instructions, visit the [installation guide](/server/livekit).
  </Step>
  <Step title="Start the server">
    Open a terminal and run the following command:

    ```bash
    poetry run 01 --server livekit --expose --qr
    ```

    This will start the 01 server with LiveKit support, expose it to the internet, and generate a QR code. You may need to wait up to 30 seconds before the code is displayed.
    
    If the server fails, you may need to restart the server a few times before it works again. We're working on resolving this as soon as possible.
  </Step>
  <Step title="Connect the app">
    Open the 01 App on your mobile device and use it to scan the QR code displayed in your terminal. This will establish a connection between your mobile device and the 01 server running on your computer.
  </Step>
</Steps>

# Settings

The 01 App offers several customizable settings to enhance your experience. These can be changed by connecting to the server, then hitting the gear icon in the upper right, and adjusting the following settings:

## <Icon icon="microphone" /> Push-to-talk

Hold the on-screen button to activate listening, or use voice activity detection for hands-free operation.

## <Icon icon="watch" /> Wearable Mode

Optimizes the interface for small screens, displaying a minimal full-screen button without the chat interface.

## <Icon icon="ear-listen" /> Always Listen for Context

Continuously gathers environmental context, even when not actively prompted. Only available when Push-to-talk is enabled.


File: ./client/desktop.mdx
<Info>This client uses the [light](/server/light) server.</Info>

The desktop client for 01 provides a simple way to interact with the 01 light server using your computer. There are two main ways to use the desktop client:

## Simulating 01 Light Hardware

To simulate the 01 light hardware device on your desktop, run:

```
poetry run 01 --client
```

This will start the client in simulation mode. You can hold the CTRL key to talk to the 01 light server, simulating the button press on the physical device.

## Running Both Server and Client

To run both the server and client simultaneously, use:

```
poetry run 01
```

This command starts both the 01 light server and the desktop client, allowing you to interact with the system immediately. The client interface will guide you through the interaction process.








File: ./client/introduction.mdx
---
title: "Introduction"
description: "Talk to the 01 Server using a client"
---

The 01 client is the user interface that captures and transmits audio, plays back responses, and provides a seamless experience across various platforms. It's designed to interact with the 01 server, which processes input, executes commands, and generates responses using Open Interpreter.

<CardGroup cols={2}>
  <Card
    title="Android & iOS App"
    icon="mobile"
    description="Our cross-platform mobile app for Android and iOS devices."
    href="/client/android-ios"
  />
  <Card
    title="ESP32 Implementation"
    icon="microchip"
    description="An implementation for ESP32 microcontrollers, perfect for IoT projects."
    href="/client/esp32"
  />
  <Card
    title="Native iOS App"
    icon="apple"
    description="A native iOS application built specifically for Apple devices."
    href="/client/native-ios"
  />
  <Card
    title="Desktop"
    icon="desktop"
    description="A Python-based desktop client for interacting with the 01 light server."
    href="/client/desktop"
  />
</CardGroup>

File: ./client/native-ios.mdx
---
title: "Native iOS App"
---

<Info>This client uses the [light](/server/light) server.</Info>

**Thank you [eladekkal](https://github.com/eladdekel) for your native iOS contribution!**

To run it on your device, you can either install the app directly through the current TestFlight [here](https://testflight.apple.com/join/v8SyuzMT), or build from the source code files in Xcode on your Mac.

### Instructions

- [Install 01 software](/software/installation) on your machine

- In Xcode, open the 'zerooone-app' project file in the project folder, change the Signing Team and Bundle Identifier, and build.

### Using the App

To use the app there are four features:

1. The speak "Button"

Made to emulate the button on the hardware models of 01, the big, yellow circle in the middle of the screen is what you hold when you want to speak to the model, and let go when you're finished speaking.

2. The settings button

Tapping the settings button will allow you to input your websocket address so that the app can properly connect to your computer.

3. The reconnect button

The arrow will be RED when the websocket connection is not live, and GREEN when it is. If you're making some changes you can easily reconnect by simply tapping the arrow button (or you can just start holding the speak button, too!).

4. The terminal button

The terminal button allows you to see all response text coming in from the server side of the 01. You can toggle it by tapping on the button, and each toggle clears the on-device cache of text.


